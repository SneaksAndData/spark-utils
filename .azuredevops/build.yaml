trigger:
  - main
  - task/*

variables:
  isMain: $[eq(variables['Build.SourceBranch'], 'refs/heads/main')]
  VENV_CACHE_DIR: $(Pipeline.Workspace)/s/sparkutils
  PIP_CACHE_DIR: $(Pipeline.Workspace)/.pip

pool:
  vmImage: ubuntu-latest

stages:
  - stage: validateAndTagCode
    displayName: Validate code and tag sources if on main
    jobs:
      - job: runTests
        container:
          image: esdcrdevelopment.azurecr.io/spark:v1.2.2-4-g67e055b-bitnami-3.2.0-python-3.9.7-0
          endpoint: esdcrdevelopment
          options: -u root -w /opt/bitnami/spark --mount type=tmpfs,destination=/home/spark
        displayName: Validate code
        steps:
          - task: Cache@2
            inputs:
              key: 'python | "$(Agent.OS)" | requirements.txt | requirements-dev.txt'
              restoreKeys: |
                python | "$(Agent.OS)"
                python
              path: $(VENV_CACHE_DIR)
            displayName: Restore venv
          - task: Cache@2
            inputs:
              key: 'pip | "$(Agent.OS)" | requirements.txt | requirements-dev.txt'
              restoreKeys: |
                pip | "$(Agent.OS)"
                pip
              path: $(PIP_CACHE_DIR)
            displayName: Restore pip cache
          - task: PipAuthenticate@1
            displayName: 'Set PIP_INDEX_URL'
            inputs:
              artifactFeeds: 'eccoSneaksAndData'
          - script: |
              set -e

              python -m virtualenv sparkutils
              source sparkutils/bin/activate
              pip install --upgrade pip

              pip install -r ./requirements.txt
              pip install -r ./requirements-dev.txt
              pip install -r ./requirements-ecco.txt
            displayName: Prepare venv
          - script: |
              set -e

              pypath=$(pwd)
              export PYTHONPATH="$pypath/src:$PYTHONPATH"

              source sparkutils/bin/activate
              find src/spark_utils -type f -name "*.py" | xargs pylint
            displayName: Lint
          - script: |
              set -e

              pypath=$(pwd)
              export PYTHONPATH="$pypath/src:$PYTHONPATH"

              source sparkutils/bin/activate
              pytest test/
            displayName: Unit test
      - job: setReleaseVersion
        displayName: Set Release Version
        dependsOn: runTests
        condition: eq(variables.isMain, true)
        steps:
          - checkout: self
            persistCredentials: 'true'
          - script: |
              set -e

              providedMajor=$MAJOR_V
              providedMinor=$MINOR_V

              currentVersion=$(git describe --tags --abbrev=7)
              currentMinor=$(echo $currentVersion | cut -d. -f2)
              currentMajor=$(echo $currentVersion | cut -d. -f1 | cut -dv -f2)

              if [[ $currentMajor -eq $providedMajor ]] && [[ $providedMinor -eq $currentMinor ]];
              then
                currentRevision=$(echo $(echo $currentVersion | rev | cut -d. -f1) | rev | cut -d- -f1)
                nextRevision=$(( currentRevision + 1 ))
              else
                nextRevision='0'
              fi

              nextVersion="v$providedMajor.$providedMinor.$nextRevision"
              git tag $nextVersion
              git push origin $nextVersion
            displayName: 'Update released version'
            env:
              MAJOR_V: $(MAJOR_V)
              MINOR_V: $(MINOR_V)
  - stage: buildDistribution
    displayName: Build distribution
    dependsOn: validateAndTagCode
    jobs:
      - job: buildAndPublish
        displayName: Run setuptools and publish
        condition: and( not(failed()), not(canceled()) )
        steps:
          - script: |
              set -e

              pip install virtualenv
              export PYTHONPATH="./:$PYTHONPATH"
              python -m virtualenv sparkutils

              source sparkutils/bin/activate
              pip install --upgrade pip
              pip install --upgrade twine build

              python -m build --sdist --wheel
            displayName: Create source distribution and a wheel
          - publish: $(System.DefaultWorkingDirectory)/dist
            artifact: dist
            displayName: Publish source as build artifact
          - task: PipAuthenticate@1
            displayName: Set pip index url
            inputs:
              artifactFeeds: 'eccoSneaksAndData'
          - script: |
              set -e

              source sparkutils/bin/activate
              pip_password=$(echo $(PIP_INDEX_URL) | cut -d: -f3 | cut -d@ -f1)

              python3 -m twine upload --verbose --non-interactive --repository-url https://pkgs.dev.azure.com/eccoSneaksAndData/_packaging/eccoSneaksAndData/pypi/upload --username build --password $pip_password dist/*
            condition: eq(variables.isMain, true)
            displayName: Publish to PyPi

